{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithinrk11/FlowCast/blob/main/Test_dataset_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test dataset generator"
      ],
      "metadata": {
        "id": "tecdFDNobK2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The below code cell generates 3 types of datasets:\n",
        ">* `noisy_crowd_data2.csv`\n",
        "* `test_data.csv`\n",
        "* `data_no_lag.csv`\n",
        "###The `noisy_crowd_data2.csv` file consists of dataset with all major details such as crowd type, lag features, noisy crowd count, etc.\n",
        "\n",
        "###The `test_data.csv` file is modified dataset of the noisy_crowd_count_data2 file where we have dropped the crowd type column.\n",
        "\n",
        "###The `data_no_lag.csv` is another modified file that does not include the lag features and crowd type columns."
      ],
      "metadata": {
        "id": "i75ijeQ6e-EO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wxCiLn1bFdu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Define the time range for the dataset (e.g., hourly data for a year)\n",
        "start_date = pd.to_datetime('2023-01-01 09:00:00')\n",
        "end_date = pd.to_datetime('2023-12-31 23:00:00')\n",
        "date_range = pd.date_range(start=start_date, end=end_date, freq='H')  # Hourly data\n",
        "\n",
        "# Create a DataFrame to store the synthetic data\n",
        "data = pd.DataFrame({'Timestamp': date_range})\n",
        "\n",
        "# Generate synthetic crowd count and categorize crowd type\n",
        "def generate_crowd_data(hour):\n",
        "    # Simulate different crowd patterns\n",
        "    if 9 <= hour < 12:\n",
        "        crowd_count = random.randint(10, 50)  # Morning - low crowd\n",
        "    elif 12 <= hour < 15:\n",
        "        crowd_count = random.randint(50, 100)  # Afternoon - moderate crowd\n",
        "    elif 15 <= hour < 18:\n",
        "        crowd_count = random.randint(100, 150)  # Evening - high crowd\n",
        "    else:\n",
        "        crowd_count = random.randint(20, 80)  # Night - lower crowd\n",
        "\n",
        "    # Categorize crowd type\n",
        "    if crowd_count <= 30:\n",
        "        crowd_type = \"Low Crowd\"\n",
        "    elif 30 < crowd_count <= 70:\n",
        "        crowd_type = \"Moderate Crowd\"\n",
        "    else:\n",
        "        crowd_type = \"High Crowd\"\n",
        "\n",
        "    return crowd_count, crowd_type\n",
        "\n",
        "data['Crowd_Count'], data['Crowd_Type'] = zip(*[generate_crowd_data(hour) for hour in data['Timestamp'].dt.hour])\n",
        "\n",
        "# Extract day, date, day name, and month name information\n",
        "data['Day'] = data['Timestamp'].dt.day\n",
        "data['Date'] = data['Timestamp'].dt.date\n",
        "data['Day_Name'] = data['Timestamp'].dt.strftime('%A')  # Get day name\n",
        "data['Month_Name'] = data['Timestamp'].dt.strftime('%B')  # Get month name\n",
        "#--------------------------------------------------------------------------------#\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Encode the Crowd_Type column\n",
        "label_encoder = LabelEncoder()\n",
        "data['Crowd_Type_Label'] = label_encoder.fit_transform(data['Crowd_Type'])\n",
        "\n",
        "# Create lag features for Crowd_Count and Timestamp\n",
        "num_lags = 3  # You can adjust the number of lag hours as needed\n",
        "for lag in range(1, num_lags + 1):\n",
        "    data[f'Prev_Crowd_Count_{lag}'] = data['Crowd_Count'].shift(lag)\n",
        "    data[f'Prev_Timestamp_{lag}'] = data['Timestamp'].shift(lag)\n",
        "\n",
        "# Drop rows with missing values (due to lag features)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Now you have a supervised dataset with input features and target labels\n",
        "# The input features include the lagged Crowd_Count and Timestamp columns\n",
        "# The target label is Crowd_Type_Label\n",
        "#--------------------------------------------------------------------------------#\n",
        "\n",
        "\n",
        "# Introduce random noise to the 'Crowd_Count' feature\n",
        "np.random.seed(42)  # Set a seed for reproducibility\n",
        "noise = np.random.normal(loc=0, scale=2, size=len(data))  # Adjust the scale as needed\n",
        "data['Noisy_Crowd_Count'] = data['Crowd_Count'] + noise\n",
        "\n",
        "# Save the dataset with noisy crowd count to a new CSV file\n",
        "data.to_csv('noisy_crowd_data2.csv', index=False)\n",
        "#--------------------------------------------------------------------------------#\n",
        "\n",
        "\n",
        "# Load the noisy crowd data CSV file\n",
        "data = pd.read_csv('noisy_crowd_data2.csv')\n",
        "\n",
        "# Drop the 'Crowd_Type' column\n",
        "data_test = data.drop(columns=['Crowd_Type', 'Crowd_Type_Label'])\n",
        "\n",
        "# Save the test dataset to a new CSV file\n",
        "data_test.to_csv('test_data.csv', index=False)\n",
        "#--------------------------------------------------------------------------------#\n",
        "\n",
        "# Drop the lag features\n",
        "lag_columns = [col for col in data.columns if 'Prev_' in col]\n",
        "data_no_lag = data.drop(columns=lag_columns)\n",
        "\n",
        "# Save the dataset without lag features to a new CSV file\n",
        "data_no_lag.to_csv('data_no_lag.csv', index=False)"
      ]
    }
  ]
}